defaults:
  - default
  - _self_

# checkpoint
checkpoint_path: '/work/09840/codyrushing/ls6/20qcheck'
save_path: '/work/09840/codyrushing/ls6/20qcheck'
cache_dir: '/work/09840/codyrushing/ls6/20qcache'

# env
env_name: twenty_questions
env_load_path: '/work/09840/codyrushing/ls6/models/20q_t5_oracle.pt'



# model
agent_type: 'archer_llm'
policy_lm : '/work/09840/codyrushing/ls6/models/Mistral-7B-Instruct-v0.2'
max_new_tokens: 64
use_lora: True
eos_str: null

capacity: 100000 #replay buffer size
rollout_size: 32 #number of rollout trajectories for each update
eval_size: 32 #number of trajectories for evaluation
batch_size: 4
iterations: 2000 #total number of iterations
epochs: 20 #number of epochs for the critic each iteration
actor_epochs: 1 #number of epochs for the actor each iteration
warmup_iter: 20 #number of iterations without updating the policy
grad_accum_steps: 64
do_sample: True
temperature: 1.0
critic_lr: 1e-5
lm_lr: 2e-6
env_idx: null #set to null if don't want to reset to a specific environment
gamma: 0.95 #discount factor
tau: 0.1 #soft update parameter
max_grad_norm: 1.0

# wandb logging
use_wandb: True
project_name: 'llm_rl_20qsubset'
run_name: 'archer-acc-llm-1e-6-subset'

use_bfloat16: True