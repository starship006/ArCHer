defaults:
  - default
  - _self_

# checkpoint
checkpoint_path: '/work/09840/codyrushing/ls6/checkpoints'

#  '/Users/codyrushing/Documents/dev/GitHub/seller_agents/checkpoints/sellerbot.pt'
save_path: '/work/09840/codyrushing/ls6/checkpoints'
cache_dir: '/work/.cache'
#model_path: '~/models/Llama-2-7b-hf'
#model_path: '~/models/gpt2'

# if importing from dataset
model_path: '/work/09840/codyrushing/ls6/models/Mistral-7B-Instruct-v0.2'

# env
env_name: seller_env
env_load_path: 'NA'

# model
agent_type: 'archer_llm'
#policy_lm : 'meta-llama/Llama-2-7b-hf'
policy_lm : '/work/09840/codyrushing/ls6/models/Mistral-7B-Instruct-v0.2'
critic_lm : '/work/09840/codyrushing/ls6/models/roberta-base'


#policy_lm : 'openai-community/gpt2'
max_new_tokens: 75 # yeah we jut need everything shorter...
use_lora: True  # CHANGED
eos_str: null


# training hyperparameters
capacity: 100000 #replay buffer size
rollout_size: 24 # 128 #number of rollout trajectories for each update | the number of trajectories on each iteration # MAKE SURE THIS IS MULTIPLE OF MIN(4, BATCH_SIZE)  while capping is still in
eval_size: 6 # 16 #number of trajectories for evaluation
batch_size: 64 # 8 
iterations: 2000 #total number of iterations
epochs: 15 # 20 #50 #number of epochs for the critic each iteration
actor_epochs: 1 #number of epochs for the actor each iteration
warmup_iter: 20 # number of iterations without updating the policy
grad_accum_steps: 12
do_sample: True # added later
temperature: 1.0 # added later 
critic_lr: 1e-5
lm_lr: 2e-6
env_idx: null #set to null if don't want to reset to a specific environment
gamma: 0.95 #discount factor
tau: 0.1 #soft update parameter
max_grad_norm: 1.0

# wandb logging
use_wandb: True
project_name: 'seller_bot'
run_name: 'seller_bot'

# other stuff that needs to get config'd because isc
save_freq: 2 # VERY FREQUENT CHECKPOINTING!
eval_freq: 4

use_bfloat16: True